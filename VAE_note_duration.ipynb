{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load parts with durations\n",
    "part1 = pd.read_csv(\"data_processed/data_part1.csv\")\n",
    "part2 = pd.read_csv(\"data_processed/data_part2.csv\")\n",
    "reconstructed_dataset = pd.read_csv(\"data_processed/reconstructed_ordered_events.csv\")\n",
    "# Merge them vertically\n",
    "duration_df = pd.concat([part1, part2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences: 2775\n",
      "Durations: 2775\n",
      "Seq 0 = 17989, Dur = 2429\n",
      "Seq 1 = 17256, Dur = 1813\n",
      "Seq 2 = 11722, Dur = 1248\n",
      "Seq 3 = 13755, Dur = 1379\n",
      "Seq 4 = 11598, Dur = 1357\n"
     ]
    }
   ],
   "source": [
    "print(\"Sequences:\", len(reconstructed_dataset))\n",
    "print(\"Durations:\", len(duration_df))\n",
    "\n",
    "# Optional: check a few row lengths\n",
    "for i in range(5):\n",
    "    print(f\"Seq {i} = {len((reconstructed_dataset['sequence'][i]))}, Dur = {len(eval(duration_df['durations'][i]))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = reconstructed_dataset.copy()\n",
    "combined_df['durations'] = duration_df['durations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"data_processed/reconstructed_with_durations.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, reconstructed_df):\n",
    "        \"\"\"\n",
    "        Build vocabulary of unique (note/chord, duration) string tokens.\n",
    "        \"\"\"\n",
    "        self.token_set = set()\n",
    "\n",
    "        for i in range(len(reconstructed_df)):\n",
    "            sequence = reconstructed_df['sequence'][i]\n",
    "            durations = reconstructed_df['durations'][i]\n",
    "\n",
    "            if isinstance(sequence, str):\n",
    "                sequence = eval(sequence)\n",
    "            if isinstance(durations, str):\n",
    "                durations = eval(durations)\n",
    "\n",
    "            assert len(sequence) == len(durations)\n",
    "\n",
    "            for event, duration in zip(sequence, durations):\n",
    "                if isinstance(event, list):\n",
    "                    note_part = \"-\".join(map(str, sorted(event)))\n",
    "                else:\n",
    "                    note_part = str(event)\n",
    "                token = f\"{note_part}_{duration}\"\n",
    "                self.token_set.add(token)\n",
    "\n",
    "        self.tokens = sorted(self.token_set)\n",
    "        self.token_to_idx = {token: idx for idx, token in enumerate(self.tokens)}\n",
    "        self.idx_to_token = {idx: token for idx, token in enumerate(self.tokens)}\n",
    "        self.vocab_size = len(self.tokens)\n",
    "\n",
    "    def encode_event(self, token):\n",
    "        \"\"\"Convert token string to index\"\"\"\n",
    "        return self.token_to_idx[token]\n",
    "\n",
    "    def decode_event(self, idx):\n",
    "        \"\"\"Convert index back to token string\"\"\"\n",
    "        return self.idx_to_token[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MusicEventDataset(Dataset):\n",
    "    def __init__(self, reconstructed_df, vocab, seq_length=50):\n",
    "        \"\"\"\n",
    "        Constructs (input_seq, target_token) pairs from note+duration tokens.\n",
    "\n",
    "        Args:\n",
    "            reconstructed_df: DataFrame with 'sequence' and 'durations' columns\n",
    "            vocab: Vocabulary object with encode_event(token: str) -> int\n",
    "            seq_length: Length of input sequence\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab = vocab\n",
    "\n",
    "        for i in range(len(reconstructed_df)):\n",
    "            sequence = reconstructed_df['sequence'][i]\n",
    "            durations = reconstructed_df['durations'][i]\n",
    "\n",
    "            if isinstance(sequence, str):\n",
    "                sequence = eval(sequence)\n",
    "            if isinstance(durations, str):\n",
    "                durations = eval(durations)\n",
    "\n",
    "            assert len(sequence) == len(durations), \"Length mismatch\"\n",
    "\n",
    "            n_events = len(sequence)\n",
    "            if n_events <= seq_length:\n",
    "                continue\n",
    "\n",
    "            for j in range(n_events - seq_length):\n",
    "                input_tokens = []\n",
    "                for e, d in zip(sequence[j:j+seq_length], durations[j:j+seq_length]):\n",
    "                    token = self.tokenize_combined(e, d)\n",
    "                    input_tokens.append(self.vocab.encode_event(token))\n",
    "\n",
    "                target_event = sequence[j + seq_length]\n",
    "                target_duration = durations[j + seq_length]\n",
    "                target_token = self.tokenize_combined(target_event, target_duration)\n",
    "                target_encoded = self.vocab.encode_event(target_token)\n",
    "\n",
    "                self.samples.append((input_tokens, target_encoded))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, target_token = self.samples[idx]\n",
    "\n",
    "        input_tensor = torch.tensor(input_seq, dtype=torch.long)\n",
    "        target_tensor = torch.tensor(target_token, dtype=torch.long)\n",
    "\n",
    "        return input_tensor, target_tensor\n",
    "\n",
    "    def tokenize_combined(self, event, duration):\n",
    "        \"\"\"\n",
    "        Convert event + duration into a consistent string token, e.g. \"45-46_0.25\"\n",
    "        \"\"\"\n",
    "        if isinstance(event, list):\n",
    "            note_part = \"-\".join(map(str, sorted(event)))\n",
    "        else:\n",
    "            note_part = str(event)\n",
    "        return f\"{note_part}_{duration}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence shape: torch.Size([16])\n",
      "Next event shape: torch.Size([])\n",
      "Input sequence (multi-hot vectors): tensor([423892,  55161,  55080, 154382, 154382, 154381, 124192, 154381, 154382,\n",
      "         55086, 288403, 124192, 154381, 361715, 170947, 170947])\n",
      "Next event (multi-hot vector): tensor(53144)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data_processed/reconstructed_with_durations.csv\")\n",
    "\n",
    "vocab = Vocabulary(df)\n",
    "\n",
    "dataset = MusicEventDataset(df, vocab=vocab, seq_length=16)\n",
    "\n",
    "x, y = dataset[0]\n",
    "\n",
    "print(\"Input sequence shape:\", x.shape)\n",
    "print(\"Next event shape:\", y.shape)\n",
    "print(\"Input sequence (multi-hot vectors):\", x)\n",
    "print(\"Next event (multi-hot vector):\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]  # discard labels if passed as (x, y)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            # Compute reconstruction loss\n",
    "            reconstruction_loss = tf.reduce_sum(\n",
    "                sparse_categorical_crossentropy(data, reconstruction), axis=1\n",
    "            )\n",
    "\n",
    "            # Compute KL divergence\n",
    "            kl_loss = -0.5 * tf.reduce_sum(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n",
    "            )\n",
    "\n",
    "            total_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128\n",
    "seq_length = 16\n",
    "latent_dim = 32\n",
    "\n",
    "# Encoder\n",
    "encoder_input = Input(shape=(seq_length,))\n",
    "x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(encoder_input)  # shape: (batch, seq_length, embedding_dim)\n",
    "x = Flatten()(x)\n",
    "z_mean = Dense(latent_dim)(x)\n",
    "z_log_var = Dense(latent_dim)(x)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(encoder_input, [z_mean, z_log_var, z])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape, TimeDistributed\n",
    "\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "x = Dense(seq_length * embedding_dim, activation=\"relu\")(decoder_input)\n",
    "x = Reshape((seq_length, embedding_dim))(x)\n",
    "decoder_output = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(x)\n",
    "\n",
    "decoder = Model(decoder_input, decoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape, TimeDistributed\n",
    "\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "x = Dense(seq_length * embedding_dim, activation=\"relu\")(decoder_input)\n",
    "x = Reshape((seq_length, embedding_dim))(x)\n",
    "decoder_output = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(x)\n",
    "\n",
    "decoder = Model(decoder_input, decoder_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m vae \u001b[38;5;241m=\u001b[39m VAE(encoder, decoder)\n\u001b[1;32m      2\u001b[0m vae\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m vae\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx_train\u001b[49m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=\"adam\")\n",
    "vae.fit(x_train, epochs=20, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
