{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca1deee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "root = 'data_processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd1042a",
   "metadata": {},
   "source": [
    "# Generation with Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c8a02",
   "metadata": {},
   "source": [
    "To establish a baseline of music generation that we can improve on, we use Recurrent Neural Networks. We formulate the problem as a next-note prediciton problem. This method is quite similar to  recurrence-based language models that are used in NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5941b",
   "metadata": {},
   "source": [
    "The input is sequential, but unlike words in NLP, timing and dynamics (duration, velocity, offset) matter a lot in music. To be able to predict notes/chords + durations + offsets + velocities we might need multi-output heads (e.g., softmax for notes/chords/velocities, regression for durations/offsets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8a953e",
   "metadata": {},
   "source": [
    "## Import Dataset and Definition of Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8ae12",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ff04479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse_all_columns(df):\n",
    "    \"\"\"\n",
    "    Parse all columns in a DataFrame to numeric, coercing errors.\n",
    "    \"\"\"\n",
    "    df['notes'] = df['notes'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['chords'] = df['chords'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['velocities'] = df['velocities'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['durations'] = df['durations'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['offsets'] = df['offsets'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['ordered_events'] = df['ordered_events'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "def load_dataframe_from_two_csvs(file1, file2):\n",
    "    \"\"\"\n",
    "    Load and concatenate two CSV files into a single pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    full_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    full_df = safe_parse_all_columns(full_df)\n",
    "\n",
    "    return full_df\n",
    "\n",
    "def save_dataframe_to_two_csvs(df, file1, file2):\n",
    "    \"\"\"\n",
    "    Split a DataFrame in half and save it into two CSV files.\n",
    "    \"\"\"\n",
    "    halfway = len(df) // 2\n",
    "    df.iloc[:halfway].to_csv(file1, index=False)\n",
    "    df.iloc[halfway:].to_csv(file2, index=False)\n",
    "\n",
    "def save_dataframe_to_one_csv(df, file):\n",
    "    \"\"\"\n",
    "    Save a DataFrame to a single CSV file.\n",
    "    \"\"\"\n",
    "    df.to_csv(file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d769e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = root + 'data_part1.csv'\n",
    "file2 = root + 'data_part2.csv'\n",
    "\n",
    "df = load_dataframe_from_two_csvs(file1, file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab83a2a",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "693eef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_chord_to_list(chord):\n",
    "    \"\"\"\n",
    "    Convert a chord string to a list of integers.\n",
    "    \"\"\"\n",
    "    if isinstance(chord, str):\n",
    "        print([int(x) for x in chord.split(',') if x.isdigit()])\n",
    "        return [int(x) for x in chord.split(',') if x.isdigit()]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd8d1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_ordered_events(df):\n",
    "    \"\"\"\n",
    "    Reconstruct the ordered list of events (notes and chords) for each song.\n",
    "    \"\"\"\n",
    "    sequences  = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        idx_note = 0\n",
    "        idx_chord = 0\n",
    "        reconstructed = []\n",
    "\n",
    "        for element in df['ordered_events'][i]:\n",
    "            if element == 'n':\n",
    "                reconstructed.append(df['notes'][i][idx_note])\n",
    "                idx_note += 1\n",
    "            elif element == 'c':\n",
    "                parsed_chord = parse_chord_to_list(df['chords'][i][idx_chord])\n",
    "                reconstructed.append(df['chords'][i][idx_chord])\n",
    "                idx_chord += 1\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown event type: {e}\")\n",
    "        \n",
    "        sequences.append(reconstructed)\n",
    "\n",
    "    reconstructed_dataset = pd.DataFrame({'sequence': sequences})\n",
    "    reconstructed_dataset.index.name = 'index'\n",
    "\n",
    "    return reconstructed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75cca658",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe_to_one_csv(reconstruct_ordered_events(df), root + 'reconstructed_ordered_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467cf9b7",
   "metadata": {},
   "source": [
    "## Predict only Events (Notes and Chords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a1e8d",
   "metadata": {},
   "source": [
    "### Creating the data: Fixed number of events "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ace4b",
   "metadata": {},
   "source": [
    "Idea for creating the input sequences:\n",
    "- we take subsets of the list of events representing each song \n",
    "- we take the next event of each subset as corresponding training output sequences\n",
    "\n",
    "This is easy to implement and we will have a consistent sequence lenght for batching, but we are ignoring the timing aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2ae116",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [8, 16, 32, 64, 128]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1bbac4",
   "metadata": {},
   "source": [
    "## Predict Events + Durations + Offsets + Velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bd11a7",
   "metadata": {},
   "source": [
    "### Creating the data: Fixed time window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8752074a",
   "metadata": {},
   "source": [
    "The input is sequential, but unlike words in NLP, timing and dynamics (duration, velocity, offset) matter a lot in music. To be able to predict notes/chords + durations + offsets + velocities we might need multi-output heads (e.g., softmax for notes/chords/velocities, regression for durations/offsets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1ebed",
   "metadata": {},
   "source": [
    "This method respects the temporal structure of the music, but batching becomes trickier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
