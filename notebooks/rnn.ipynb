{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca1deee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import random\n",
    "import time\n",
    "\n",
    "from music21 import stream, note, chord, midi, converter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "root = 'data_processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd1042a",
   "metadata": {},
   "source": [
    "# Generation with Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c8a02",
   "metadata": {},
   "source": [
    "We begin our music generation experiments with Recurrent Neural Networks (RNNs), which are a natural fit for sequential data.  \n",
    "The task is framed as a next-event prediction problem, where the model must predict the next note or chord in a sequence based on prior context.\n",
    "\n",
    "This approach is conceptually similar to language modeling in NLP, but musical sequences present unique challenges:\n",
    "- Timing and dynamics (duration, velocity, offset) are critical, unlike in most text-based models.\n",
    "- Events can be single notes or chords, requiring flexible representations and outputs.\n",
    "\n",
    "Our earlier data analysis revealed strong short-term dependencies (e.g., repeated notes, stable motifs) and non-uniform distributions across pitch, velocity, and duration.  \n",
    "This justifies the use of an RNN, which can learn to capture these local patterns and regularities across sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f8ae12",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff04479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse_all_columns_df(df):\n",
    "    \"\"\"\n",
    "    Parse all columns in a DataFrame to numeric, coercing errors.\n",
    "    \"\"\"\n",
    "    df['notes'] = df['notes'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['chords'] = df['chords'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['velocities'] = df['velocities'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['durations'] = df['durations'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['offsets'] = df['offsets'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['ordered_events'] = df['ordered_events'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "def load_dataframe_from_two_csvs(file1, file2):\n",
    "    \"\"\"\n",
    "    Load and concatenate two CSV files into a single pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    full_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    full_df = safe_parse_all_columns_df(full_df)\n",
    "\n",
    "    return full_df\n",
    "\n",
    "def save_dataframe_to_two_csvs(df, file1, file2):\n",
    "    \"\"\"\n",
    "    Split a DataFrame in half and save it into two CSV files.\n",
    "    \"\"\"\n",
    "    halfway = len(df) // 2\n",
    "    df.iloc[:halfway].to_csv(file1, index=False)\n",
    "    df.iloc[halfway:].to_csv(file2, index=False)\n",
    "\n",
    "def load_dataframe_from_one_csv(file):\n",
    "    \"\"\"\n",
    "    Load a DataFrame from a single CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_dataframe_to_one_csv(df, file):\n",
    "    \"\"\"\n",
    "    Save a DataFrame to a single CSV file.\n",
    "    \"\"\"\n",
    "    df.to_csv(file, index=True)\n",
    "\n",
    "def load_reconstructed_events(file):\n",
    "    \"\"\"\n",
    "    Loads the reconstructed events CSV and safely parses the 'sequence' column,\n",
    "    converting notes to integers and chords to lists of integers.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    def safe_parse(seq_str):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(seq_str)\n",
    "            if not isinstance(parsed, list):\n",
    "                raise ValueError(\"Parsed sequence is not a list\")\n",
    "\n",
    "            normalized = []\n",
    "            for el in parsed:\n",
    "                if isinstance(el, list):\n",
    "                    normalized.append([int(x) for x in el])\n",
    "                else:\n",
    "                    normalized.append(int(el))\n",
    "            return normalized\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing sequence: {seq_str}\")\n",
    "            raise e\n",
    "\n",
    "    df['sequence'] = df['sequence'].apply(safe_parse)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d769e5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = root + 'data_part1.csv'\n",
    "file2 = root + 'data_part2.csv'\n",
    "\n",
    "df = load_dataframe_from_two_csvs(file1, file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab83a2a",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8d1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_chord_to_list(chord):\n",
    "    \"\"\"\n",
    "    Convert a chord string to a list of integers.\n",
    "    \"\"\"\n",
    "    if isinstance(chord, str):\n",
    "        print([int(x) for x in chord.split(',') if x.isdigit()])\n",
    "        return [int(x) for x in chord.split(',') if x.isdigit()]\n",
    "    return []\n",
    "\n",
    "def reconstruct_ordered_events(df):\n",
    "    \"\"\"\n",
    "    Reconstruct the ordered list of events (notes and chords) for each song.\n",
    "    \"\"\"\n",
    "    sequences  = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        idx_note = 0\n",
    "        idx_chord = 0\n",
    "        reconstructed = []\n",
    "\n",
    "        for element in df['ordered_events'][i]:\n",
    "            if element == 'n':\n",
    "                reconstructed.append(df['notes'][i][idx_note])\n",
    "                idx_note += 1\n",
    "            elif element == 'c':\n",
    "                parsed_chord = parse_chord_to_list(df['chords'][i][idx_chord])\n",
    "                reconstructed.append(df['chords'][i][idx_chord])\n",
    "                idx_chord += 1\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown event type: {e}\")\n",
    "        \n",
    "        sequences.append(reconstructed)\n",
    "\n",
    "    reconstructed_dataset = pd.DataFrame({'sequence': sequences})\n",
    "    reconstructed_dataset.index.name = 'index'\n",
    "\n",
    "    return reconstructed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cca658",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe_to_one_csv(reconstruct_ordered_events(df), root + 'reconstructed_ordered_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467cf9b7",
   "metadata": {},
   "source": [
    "## Event-Based Sequence Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a1e8d",
   "metadata": {},
   "source": [
    "### Creating the data: Fixed-length Event Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ace4b",
   "metadata": {},
   "source": [
    "To train our RNN, we transform each musical track into a sequence of discrete eventsâ€”either a note or a chord.\n",
    "\n",
    "We apply a sliding-window approach:\n",
    "- From each track, we extract fixed-length input sequences (subsets of the event list).\n",
    "- The model learns to predict the next event given the current context.\n",
    "\n",
    "This approach is straightforward and effective for training, as it allows for batching sequences of consistent length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619924df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    \"\"\"\n",
    "    Builds a vocabulary of unique musical events (notes and chords) found in the dataset.\n",
    "    Handles encoding to integer IDs and decoding back to event form.\n",
    "    \"\"\"\n",
    "    def __init__(self, reconstructed_df):\n",
    "        self.notes = set()\n",
    "        for i in range(len(reconstructed_df)):\n",
    "            sequence = reconstructed_df['sequence'][i]\n",
    "            for event in sequence:\n",
    "                if isinstance(event, list):\n",
    "                    for note in event:\n",
    "                        self.notes.add(note)\n",
    "                else:\n",
    "                    self.notes.add(event)\n",
    "\n",
    "        self.notes = sorted(self.notes)\n",
    "        self.note_to_idx = {note: idx for idx, note in enumerate(self.notes)}\n",
    "        self.idx_to_note = {idx: note for idx, note in enumerate(self.notes)}\n",
    "        self.vocab_size = len(self.notes)\n",
    "\n",
    "    def encode_event(self, event):\n",
    "        \"\"\"\n",
    "        Encode an event as a multi-hot vector over single notes.\n",
    "        \"\"\"\n",
    "        vec = np.zeros(self.vocab_size, dtype=np.float32)\n",
    "        if isinstance(event, list):\n",
    "            for note in event:\n",
    "                vec[self.note_to_idx[note]] = 1.0\n",
    "        else:\n",
    "            vec[self.note_to_idx[event]] = 1.0\n",
    "        return vec\n",
    "\n",
    "    def decode_event(self, vec, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Decode multi-hot vector to list of notes.\n",
    "        \"\"\"\n",
    "        indices = np.where(vec >= threshold)[0]\n",
    "        notes = [self.idx_to_note[idx] for idx in indices]\n",
    "        if len(notes) == 1:\n",
    "            return notes[0]\n",
    "        else:\n",
    "            return notes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5456a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicEventDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Constructs input-target pairs from event sequences for next-event prediction.\n",
    "\n",
    "    Each sample consists of a subsequence of fixed length (input)\n",
    "    and the immediate next event (target).\n",
    "    \"\"\"\n",
    "    def __init__(self, reconstructed_df, vocab, seq_length=50):\n",
    "        self.samples = []\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab = vocab\n",
    "\n",
    "        for row_index in range(len(reconstructed_df)):\n",
    "            sequence = reconstructed_df['sequence'][row_index]\n",
    "            n_events = len(sequence)\n",
    "\n",
    "            if n_events <= seq_length:\n",
    "                continue\n",
    "\n",
    "            for i in range(n_events - seq_length):\n",
    "                input_seq = sequence[i : i + seq_length]\n",
    "                target_event = sequence[i + seq_length]\n",
    "                self.samples.append((input_seq, target_event))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, target_event = self.samples[idx]\n",
    "\n",
    "        input_encoded = np.array([self.vocab.encode_event(event) for event in input_seq], dtype=np.float32)\n",
    "        input_tensor = torch.tensor(input_encoded)\n",
    "\n",
    "        target_encoded = self.vocab.encode_event(target_event)\n",
    "        target_tensor = torch.tensor(target_encoded, dtype=torch.float32)\n",
    "\n",
    "        return input_tensor, target_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13e88b8",
   "metadata": {},
   "source": [
    "### Model, Metrics and Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab794652",
   "metadata": {},
   "source": [
    "We implement a Recurrent Neural Network (RNN) to model musical event sequences.  \n",
    "Given a sequence of previous events (notes or chords), the model learns to predict the next event.\n",
    "\n",
    "We use an LSTM-based architecture and evaluate performance using cross-validation across:\n",
    "- Different input sequence lengths\n",
    "- Different hidden layer sizes\n",
    "\n",
    "This helps us identify optimal architectural configurations and avoid overfitting to a specific temporal window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac442718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicEventRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple LSTM-based RNN for next-event prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(MusicEventRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=input_size, hidden_size=hidden_size, \n",
    "                           num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        out, hidden = self.rnn(x, hidden)  \n",
    "        out_last = out[:, -1, :]\n",
    "        out = self.fc(out_last)\n",
    "\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33fe121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_dataset = load_reconstructed_events(root + 'reconstructed_ordered_events.csv')\n",
    "vocab = Vocabulary(reconstructed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataset, epochs=10, batch_size=32, seq_length=16, val_split=0.1, print_every=5, checkpoint_path=\"best_model.pth\"):\n",
    "    \"\"\"\n",
    "    Train an RNN model on the given dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader, 1):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if batch_idx % print_every == 0 or batch_idx == len(train_loader):\n",
    "                avg_loss = running_loss / batch_idx\n",
    "                print(f\"Epoch {epoch}, Batch {batch_idx}/{len(train_loader)}, Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(\"Training done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71074343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_dataset, batch_size=128):\n",
    "    \"\"\"\n",
    "    Evaluate a trained model on a validation set.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "            outputs, _ = model(x_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    return val_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c5f963",
   "metadata": {},
   "source": [
    "To evaluate different architectural configurations, we perform cross-validation over:\n",
    "- Sequence length (8, 16, 32)\n",
    "- Hidden layer size (64, 128, 256)\n",
    "\n",
    "We use categorical cross-entropy as the loss function and train each model for a small number of epochs to compare generalization on a validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca68c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning for sequence length: 8 ===\n",
      "\n",
      "-- hidden_size=64, num_layers=1 --\n",
      "  Fold 1/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0830\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0800\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0792\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0762\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0762\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0761\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0759\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0759\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0759\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0758\n",
      "  Fold 2/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0830\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0799\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0792\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0762\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0761\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0761\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0759\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0759\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0758\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0758\n",
      "  Fold 3/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0829\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0799\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0792\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0762\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0761\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0761\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0759\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0759\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0758\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0759\n",
      "  Fold 4/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0828\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0799\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0791\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0762\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0761\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0761\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0759\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0759\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0758\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0757\n",
      "  Fold 5/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0829\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0799\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0792\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0762\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0761\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0761\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0758\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0758\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0758\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0758\n",
      "\n",
      "-- hidden_size=128, num_layers=1 --\n",
      "  Fold 1/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0805\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0785\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0780\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0760\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0759\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0758\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0756\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0756\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0755\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0755\n",
      "  Fold 2/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0806\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0785\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0781\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0760\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0758\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0758\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0755\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0755\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0755\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0756\n",
      "  Fold 3/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0808\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0787\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0781\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0759\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0759\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0758\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0756\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0755\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0755\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0756\n",
      "  Fold 4/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0807\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0786\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0781\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0759\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0759\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0758\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0755\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0755\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0755\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0755\n",
      "  Fold 5/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0805\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0785\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0780\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0759\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0758\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0758\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0755\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0755\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0755\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0755\n",
      "\n",
      "-- hidden_size=256, num_layers=1 --\n",
      "  Fold 1/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0795\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0779\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0775\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0757\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0756\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0756\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0752\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0751\n",
      "  Fold 2/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0793\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0778\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0774\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0757\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0756\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0756\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0752\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0752\n",
      "  Fold 3/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0794\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0778\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0774\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0757\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0756\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0756\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0752\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0753\n",
      "  Fold 4/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0795\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0779\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0775\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0757\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0756\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0756\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0752\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0751\n",
      "  Fold 5/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25282, Avg Loss: 0.0795\n",
      "Epoch 1, Batch 20000/25282, Avg Loss: 0.0779\n",
      "Epoch 1, Batch 25282/25282, Avg Loss: 0.0775\n",
      "Epoch 2, Batch 10000/25282, Avg Loss: 0.0757\n",
      "Epoch 2, Batch 20000/25282, Avg Loss: 0.0756\n",
      "Epoch 2, Batch 25282/25282, Avg Loss: 0.0756\n",
      "Epoch 3, Batch 10000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 20000/25282, Avg Loss: 0.0752\n",
      "Epoch 3, Batch 25282/25282, Avg Loss: 0.0752\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0753\n",
      "\n",
      "=== Tuning for sequence length: 16 ===\n",
      "\n",
      "-- hidden_size=64, num_layers=1 --\n",
      "  Fold 1/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0823\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0791\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0783\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0752\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0751\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0751\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0748\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0747\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0747\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0746\n",
      "  Fold 2/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0820\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0789\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0783\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0752\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0751\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0751\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0748\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0747\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0747\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0746\n",
      "  Fold 3/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0822\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0788\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0783\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0752\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0751\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0750\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0748\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0747\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0747\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0744\n",
      "  Fold 4/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0821\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0789\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0782\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0753\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0751\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0751\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0748\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0747\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0747\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0746\n",
      "  Fold 5/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0819\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0788\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0783\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0752\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0751\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0751\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0748\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0747\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0747\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0745\n",
      "\n",
      "-- hidden_size=128, num_layers=1 --\n",
      "  Fold 1/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0798\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0782\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0776\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0750\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0749\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0749\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0745\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0745\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0745\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0745\n",
      "  Fold 2/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0799\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0781\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0775\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0750\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0749\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0749\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0746\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0745\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0745\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0745\n",
      "  Fold 3/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0797\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0780\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0773\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0750\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0748\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0747\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0745\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0745\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0744\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0744\n",
      "  Fold 4/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0798\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0782\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0776\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0749\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0747\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0746\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0746\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0745\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0745\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0745\n",
      "  Fold 5/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0798\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0783\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0777\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0749\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0748\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0748\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0745\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0744\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0744\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0744\n",
      "\n",
      "-- hidden_size=256, num_layers=1 --\n",
      "  Fold 1/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0786\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0769\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0765\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0756\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0746\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0744\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0742\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0742\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0741\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0741\n",
      "  Fold 2/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0786\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0769\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0764\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0753\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0745\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0744\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0742\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0741\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0741\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0741\n",
      "  Fold 3/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0784\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0765\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0762\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0754\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0743\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0742\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0741\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0740\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0740\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0740\n",
      "  Fold 4/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0787\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0769\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0764\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0757\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0746\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0745\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0743\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0742\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0742\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0742\n",
      "  Fold 5/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25157, Avg Loss: 0.0788\n",
      "Epoch 1, Batch 20000/25157, Avg Loss: 0.0769\n",
      "Epoch 1, Batch 25157/25157, Avg Loss: 0.0766\n",
      "Epoch 2, Batch 10000/25157, Avg Loss: 0.0756\n",
      "Epoch 2, Batch 20000/25157, Avg Loss: 0.0746\n",
      "Epoch 2, Batch 25157/25157, Avg Loss: 0.0745\n",
      "Epoch 3, Batch 10000/25157, Avg Loss: 0.0742\n",
      "Epoch 3, Batch 20000/25157, Avg Loss: 0.0741\n",
      "Epoch 3, Batch 25157/25157, Avg Loss: 0.0741\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0741\n",
      "\n",
      "=== Tuning for sequence length: 32 ===\n",
      "\n",
      "-- hidden_size=64, num_layers=1 --\n",
      "  Fold 1/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0804\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0776\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0769\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0739\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0737\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0736\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0732\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0730\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0730\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0730\n",
      "  Fold 2/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0803\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0776\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0768\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0738\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0737\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0737\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0732\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0731\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0731\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0731\n",
      "  Fold 3/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0804\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0774\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0770\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0739\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0737\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0737\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0731\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0731\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0730\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0730\n",
      "  Fold 4/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0806\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0776\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0770\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0741\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0739\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0738\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0732\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0732\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0732\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0732\n",
      "  Fold 5/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0804\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0774\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0767\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0739\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0738\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0737\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0731\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0730\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0730\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0730\n",
      "\n",
      "-- hidden_size=128, num_layers=1 --\n",
      "  Fold 1/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0781\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0764\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0750\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0737\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0734\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0734\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0729\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0728\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0728\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0728\n",
      "  Fold 2/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0780\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0762\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0752\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0739\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0735\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0735\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0728\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0727\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0727\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0727\n",
      "  Fold 3/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0781\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0764\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0750\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0737\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0734\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0733\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0729\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0728\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0728\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0728\n",
      "  Fold 4/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0782\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0764\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0751\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0738\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0734\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0734\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0728\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0728\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0728\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0728\n",
      "  Fold 5/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0779\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0763\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0749\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0736\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0733\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0733\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0728\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0728\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0727\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0727\n",
      "\n",
      "-- hidden_size=256, num_layers=1 --\n",
      "  Fold 1/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0768\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0747\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0744\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0734\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0733\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0733\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0726\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0726\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0725\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0725\n",
      "  Fold 2/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0767\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0747\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0745\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0733\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0733\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0732\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0727\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0726\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0726\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0726\n",
      "  Fold 3/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0768\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0749\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0744\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0734\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0732\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0732\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0725\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0725\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0725\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0725\n",
      "  Fold 4/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0766\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0749\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0746\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0733\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0732\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0732\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0725\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0725\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0724\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0724\n",
      "  Fold 5/5\n",
      "Using device: cpu\n",
      "Epoch 1, Batch 10000/25032, Avg Loss: 0.0769\n",
      "Epoch 1, Batch 20000/25032, Avg Loss: 0.0751\n",
      "Epoch 1, Batch 25032/25032, Avg Loss: 0.0747\n",
      "Epoch 2, Batch 10000/25032, Avg Loss: 0.0734\n",
      "Epoch 2, Batch 20000/25032, Avg Loss: 0.0733\n",
      "Epoch 2, Batch 25032/25032, Avg Loss: 0.0731\n",
      "Epoch 3, Batch 10000/25032, Avg Loss: 0.0726\n",
      "Epoch 3, Batch 20000/25032, Avg Loss: 0.0726\n",
      "Epoch 3, Batch 25032/25032, Avg Loss: 0.0725\n",
      "Training done.\n",
      "    -> Validation Loss: 0.0725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence_lengths = [8, 16, 32]\n",
    "hidden_sizes = [64, 128, 256]\n",
    "num_layers_options = [1]\n",
    "k_folds = 5\n",
    "results = {}\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "for seq_len in sequence_lengths:\n",
    "    print(f\"\\n=== Tuning for sequence length: {seq_len} ===\")\n",
    "    dataset = MusicEventDataset(reconstructed_dataset, vocab=vocab, seq_length=seq_len)\n",
    "\n",
    "    total_size = len(dataset)\n",
    "    test_size = int(0.1 * total_size)\n",
    "    train_size = total_size - test_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=generator)\n",
    "\n",
    "    for hidden_size in hidden_sizes:\n",
    "        for num_layers in num_layers_options:\n",
    "            fold_losses = []\n",
    "            print(f\"\\n-- hidden_size={hidden_size}, num_layers={num_layers} --\")\n",
    "\n",
    "            kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "                print(f\"  Fold {fold+1}/{k_folds}\")\n",
    "                train_subset = Subset(train_dataset, train_idx)\n",
    "                val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "                model = MusicEventRNN(\n",
    "                    input_size=len(vocab),\n",
    "                    hidden_size=hidden_size,\n",
    "                    output_size=len(vocab),\n",
    "                    num_layers=num_layers\n",
    "                )\n",
    "\n",
    "                train_model(\n",
    "                    model=model,\n",
    "                    dataset=train_subset,\n",
    "                    epochs=3,\n",
    "                    batch_size=128,\n",
    "                    seq_length=seq_len,\n",
    "                    print_every=10000,\n",
    "                    checkpoint_path=None\n",
    "                )\n",
    "\n",
    "                val_loss = evaluate_model(model, val_subset, batch_size=128)\n",
    "                print(f\"    -> Validation Loss: {val_loss:.4f}\")\n",
    "                fold_losses.append(val_loss)\n",
    "\n",
    "            avg_loss = sum(fold_losses) / len(fold_losses)\n",
    "            results[(seq_len, hidden_size, num_layers)] = avg_loss\n",
    "\n",
    "print(\"\\n=== K-Fold Tuning Results ===\")\n",
    "for (seq_len, hidden_size, num_layers), val_loss in results.items():\n",
    "    print(f\"Seq Len: {seq_len}, Hidden: {hidden_size}, Layers: {num_layers} => Avg Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966fac29",
   "metadata": {},
   "source": [
    "### Final Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fc233",
   "metadata": {},
   "source": [
    "After identifying the best-performing configuration from cross-validation, we retrain the model with:\n",
    "- Sequence length: 32\n",
    "- Hidden size: 256\n",
    "- 1 recurrent layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "453049cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuing training for 5 more epochs with seq_len=32, hidden_size=256...\n",
      "Epoch 1, Batch 10000/31134 - Avg Loss So Far: 0.0727\n",
      "Epoch 1, Batch 20000/31134 - Avg Loss So Far: 0.0728\n",
      "Epoch 1, Batch 30000/31134 - Avg Loss So Far: 0.0728\n",
      "Epoch 1/5 - Avg Loss: 0.0728\n",
      "Epoch 2, Batch 10000/31134 - Avg Loss So Far: 0.0726\n",
      "Epoch 2, Batch 20000/31134 - Avg Loss So Far: 0.0726\n",
      "Epoch 2, Batch 30000/31134 - Avg Loss So Far: 0.0726\n",
      "Epoch 2/5 - Avg Loss: 0.0726\n",
      "Epoch 3, Batch 10000/31134 - Avg Loss So Far: 0.0725\n",
      "Epoch 3, Batch 20000/31134 - Avg Loss So Far: 0.0725\n",
      "Epoch 3, Batch 30000/31134 - Avg Loss So Far: 0.0725\n",
      "Epoch 3/5 - Avg Loss: 0.0725\n",
      "Epoch 4, Batch 10000/31134 - Avg Loss So Far: 0.0724\n",
      "Epoch 4, Batch 20000/31134 - Avg Loss So Far: 0.0724\n",
      "Epoch 4, Batch 30000/31134 - Avg Loss So Far: 0.0724\n",
      "Epoch 4/5 - Avg Loss: 0.0725\n",
      "Epoch 5, Batch 10000/31134 - Avg Loss So Far: 0.0723\n",
      "Epoch 5, Batch 20000/31134 - Avg Loss So Far: 0.0723\n",
      "Epoch 5, Batch 30000/31134 - Avg Loss So Far: 0.0724\n",
      "Epoch 5/5 - Avg Loss: 0.0724\n",
      "Model saved as 'music_gen_seq32_hidden256.pth'\n"
     ]
    }
   ],
   "source": [
    "seq_len = 32\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "learning_rate = 0.001\n",
    "checkpoint_path = \"music_gen_seq32_hidden256.pth\"\n",
    "\n",
    "dataset = MusicEventDataset(reconstructed_dataset, vocab=vocab, seq_length=seq_len)\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "total_size = len(dataset)\n",
    "test_size = int(0.1 * total_size)\n",
    "train_size = total_size - test_size\n",
    "train_dataset, _ = random_split(dataset, [train_size, test_size], generator=generator)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = MusicEventRNN(\n",
    "    input_size=len(vocab),\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=len(vocab),\n",
    "    num_layers=num_layers\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(f\"Continuing training for {epochs} more epochs with seq_len={seq_len}, hidden_size={hidden_size}...\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, (x_batch, y_batch) in enumerate(train_loader, start=1):\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 10000 == 0:\n",
    "            avg_loss_so_far = total_loss / batch_idx\n",
    "            print(f\"Epoch {epoch}, Batch {batch_idx}/{len(train_loader)} - Avg Loss So Far: {avg_loss_so_far:.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch}/{epochs} - Avg Loss: {avg_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), checkpoint_path)\n",
    "print(f\"Model saved as '{checkpoint_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b04ad",
   "metadata": {},
   "source": [
    "### Generate Music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c6d10",
   "metadata": {},
   "source": [
    "Once trained, we use the model to generate new musical sequences, starting from a seed and iteratively predicting the next event.\n",
    "\n",
    "We use a probabilistic sampling strategy (with temperature scaling) to ensure variation and creativity in the generated music.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e9aaed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 32\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "\n",
    "dataset = MusicEventDataset(reconstructed_dataset, vocab=vocab, seq_length=seq_len)\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "total_size = len(dataset)\n",
    "test_size = int(0.1 * total_size)\n",
    "train_size = total_size - test_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=generator)\n",
    "\n",
    "model = MusicEventRNN(\n",
    "    input_size=len(vocab),\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=len(vocab),\n",
    "    num_layers=num_layers\n",
    ")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"music_gen_seq32_hidden256.pth\", map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f44a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music_multihot(model, vocab, start_sequence, max_length=100, temperature=1.0, device='cpu', threshold=0.3):\n",
    "    \"\"\"\n",
    "    Generate music with a model that outputs multi-hot note vectors.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    generated = start_sequence.copy()\n",
    "    input_seq = torch.tensor([vocab.encode_event(ev) for ev in start_sequence], dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    hidden = None\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        with torch.no_grad():\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "            logits = output.squeeze(0)\n",
    "            probs = torch.softmax(logits / temperature, dim=0)\n",
    "\n",
    "            bernoulli_samples = torch.bernoulli(probs).int()\n",
    "            sampled = (bernoulli_samples == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "\n",
    "            if not sampled:\n",
    "                topk = probs.topk(3).indices.tolist()\n",
    "                sampled = topk[:random.randint(1, 3)]\n",
    "\n",
    "            decoded_event = [vocab.idx_to_note[idx] for idx in sampled]\n",
    "            if len(decoded_event) == 1:\n",
    "                decoded_event = decoded_event[0]\n",
    "                \n",
    "            generated.append(decoded_event)\n",
    "\n",
    "            input_seq = torch.tensor([[vocab.encode_event(decoded_event)]], dtype=torch.float32, device=device)\n",
    "\n",
    "    return generated[len(start_sequence):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e265991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_midi(events, filename=\"generated_from_test.mid\", default_duration=0.5):\n",
    "    \"\"\"\n",
    "    Convert a list of musical events into a MIDI file.\n",
    "    \"\"\"\n",
    "    part = stream.Part()\n",
    "    current_offset = 0.0\n",
    "\n",
    "    for ev in events:\n",
    "        if isinstance(ev, list):\n",
    "            m21_event = chord.Chord(ev)\n",
    "        else:\n",
    "            m21_event = note.Note(ev)\n",
    "\n",
    "        m21_event.duration = duration.Duration(default_duration)\n",
    "        part.insert(current_offset, m21_event)\n",
    "\n",
    "        current_offset += default_duration\n",
    "\n",
    "    score = stream.Score()\n",
    "    score.insert(0, part)\n",
    "\n",
    "    mf = midi.translate.music21ObjectToMidiFile(score)\n",
    "    mf.open(filename, 'wb')\n",
    "    mf.write()\n",
    "    mf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99745eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = \"generated_music_rnn/\"\n",
    "for i in range(100):\n",
    "    x, _ = test_dataset[random.randint(0, len(test_dataset)-1)]\n",
    "    start_seq = [vocab.decode_event(vec) for vec in x]\n",
    "    generated_events = generate_music_multihot(model, vocab, start_seq, max_length=50, temperature=1)\n",
    "\n",
    "    save_to_midi(generated_events, root_folder + f\"dataset/sample_{i}.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649bfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_midi_to_event_sequence(midi_path):\n",
    "    \"\"\"\n",
    "    Parses a MIDI file into a list of notes and chords.\n",
    "    Chords become lists of pitch numbers, notes stay as integers.\n",
    "    \"\"\"\n",
    "    score = converter.parse(midi_path)\n",
    "    flat = score.flat.notes\n",
    "    events = []\n",
    "\n",
    "    for el in flat:\n",
    "        if isinstance(el, note.Note):\n",
    "            events.append(el.pitch.midi)\n",
    "        elif isinstance(el, chord.Chord):\n",
    "            events.append([p.midi for p in el.pitches])\n",
    "\n",
    "    return events\n",
    "\n",
    "def prime_and_generate_from_midi(midi_path, model, vocab, max_length=50, temperature=1.0, seq_len=32, output_file=\"output.mid\", def_duration=0.5):\n",
    "    \"\"\"\n",
    "    Loads a MIDI file, extracts a sequence of notes/chords, and uses it to generate new music.\n",
    "    \"\"\"\n",
    "    original_sequence = parse_midi_to_event_sequence(midi_path)\n",
    "\n",
    "    if len(original_sequence) < seq_len:\n",
    "        raise ValueError(f\"Sequence too short: {len(original_sequence)} events (need at least {seq_len})\")\n",
    "\n",
    "    start_sequence = original_sequence[60:60+seq_len]\n",
    "\n",
    "    generated = generate_music_multihot(model, vocab, start_sequence, max_length=max_length, temperature=temperature)\n",
    "\n",
    "    save_to_midi(generated, output_file, default_duration=def_duration)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ae87451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generated_music_rnn/popular/BillieJean.mid'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_folder = \"popular_songs/\"\n",
    "name_of_song = \"BillieJean.mid\"\n",
    "to_folder = \"generated_music_rnn/popular/\"\n",
    "prime_and_generate_from_midi(from_folder + name_of_song, model, vocab, temperature=0.8, output_file=to_folder + name_of_song, def_duration=0.65)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
